The realization of psychophysical experiments imposes special requirements on both software and hardware. Most users are scientists, who in general possess no skills in fundamental computer science. In my work I will introduce a special environment, allowing a fast and uncomplicated package for those experiments in a visual domain. As a foundation I will the Python programming language, which I will extend with a special module, which in turn takes over the management of the DATAPixx graphic system. For control purposes I have included a gauge which is suitable for exact monitoring of the monitor. I forsook proprietary closed source components in order to offer free and open software. I demonstrate the functionality of the environment with an example experiment, which can become a prototype for psychophysicists to look at.

1. Introduction

The goal of psychophysics experiments in the visual domain is the determination of perceptual performance in so called near threshold perception. That which we see can differ strongly from objective reality. In one test will the reactions from a subject upon differences between specially prepared optical stimuli be investigated.

The smallest unit of the experiment is the procedure. It consists fundamentally of the following steps: a stimulus will be shown for an brief yet exact amount of time, which will then either be blended or masked with a second stimulus, after which the subject will be prompted to answer by way of a keyboard what they saw. In many cases an exact measurement of reaction time is required. The smallest presentation time possible is a frame, which is dependent on the refresh rate of the monitor. The procedure will often require repetition for different stimuli.

In figure one is depicted a so called gabor stimulus, which will be used for the examination of contrast sensitivity. The function was invented by Denis Gabor and consists of a sine wave multiplied with a gauss function. The sine function has the maximum amplitude where Gau√ü-Glocke maximum is reached, for the limiting of the amplitude, and consequently the kontrast. Through the lack of scharp transitions, the subject can't depend on map based recognition, and the results will be more accurate in light of searching for contrast sensitivity.

In order to exactly present such stimuli, one needs a special system for rendering graphics. The requirements for the realization of visual experiments distinguish themselves distinctly from the norm, which one would normally in the world of game development and multimedia rendering. The following features are key:

1. To realize the greatest luminance range, within which are possible the smallest (below the perceptual threshold) increments, which themselves are linearly arranged.

2. Temporal exactness is critical, where pictures must be shown at a given time point and must stay for an exact perceivable duration.

3. It must be ensured, that the same figure can be exactly presented in different parts of the screen with various background colours.

A conventional graphics card has 3 8 bit digital analog converters for the three colour channels (red, green, and blue). This makes 256 possible steps for each channel. This is not especially much and the difference in intensities between steps is plainly visible. In order to resolve this problem one employs external graphics rendering systems. A the moment one leading product is the "ViSaGe" system from Cambridge Research Systems. This device possesses 14 bit DACs, which allows finer distinct increments. In my work I will introduce a system which possesses 16 bit DACs thus enabling still smaller contrasts.

The Digitial to Analog Converter is normally calibrated so that the outgoing voltage for each value increases linearly. There is however a problem. The resulting onscreen luminance does not increase linearly and depends on the device. So one needs a special procedure in order to linearize the onscreen output, thereby costing unique DAC values and shrinking the available range.

The next step is the screen. Many displays advertize very idealized specifications. It suffices to go but once to the monitor department of a tech shop for something to be apparent: Different monitors show the same specifications very differently. If one is missing such a device in the lab, one is struck by a further problem: the same object changes its brightness dpending on its position and the background upon which it is shown. I have measured several devices and will in my work introduce my results. 

In order to use all this technology sensibly, one needs software which in the simplest way puts at ones disposal all necessary functionality. There exists a great amount graphics libraries, many which however feature critical deficiencies. I have tried out several packages and will share my results. Furthermore I will say a few words about how one correclty configures the operating system of the experiment computer.

To close, if one has found a workable solution, it should be measured and reviewed, whether this solution functions correctly. There are several luminance measuring devices on the market, yet most are too slow to allow exact frame control at higher frame rates. I have developed a unique device which fulfills this requirement.

In order to illustrate how the whole environment could work in the real world, at the end of my work I introduce a relatively complex experiment, which employs all functionality.

2 Graphics rendering systems and their features

Through the search for a good graphic system for experiments does one bump into new concepts, at this point I would quickly like to explain.

A normal graphics card has an 8 bit DAC for each color channel. This enables the display of 2^24 different colours on the monitor. When one wants to limit to one colour or greyscale, there remains only 256 colours left. In order to extend this range one employs external hardware with DACs with larger words. Most picture formats use only 8 bit values for coding colours, whether for RGB or greyscale. How does one reach these additonal values? This comes with the help of a lookup table (LUT). The alternative will be denoted by colour lookup table (CLUT). This table has 256 entries and specifies for each index the value for the DAC which will be used by the renderer for the monitor. The values in the picture data serve has indices for this table. Concisely, the table serves the translation from colour values from the data into real values which the graphics card uses. The latest graphics cards from Nvidia and ATI come already with 10 bit DACs, but it is improbable that this word size will increase, because for a general user is this more than enough.

Now can one do the following: One outputs an image and alters the lookup table. The onscreen image changes, but no new picture information is transferred. So, for example, one can change the contrast of an image without always having to calculate new pixel values. If one quickly changes the LUTs, a so called Palette animation arises. A quick sequential changing of the LUTs is called LUT cycling.

LUT cycling works well, if one wants to animation clear patterns or to would like to vary the entries of a static image. With animations one must quickly show whole new images one after the other. For that one employs page cycling. A row of image pages will be prepared and shown from a sequence of time points.

The DACs from graphics cards are normally calibrated so that the output voltage increases linearly for each continuing value. The resulting luminance however does not increase linearly with a CRT Monitor. The progression usually looks as depicted in figure 2, and resembles a power function. The exponent of this function will be called gamma, and is different for various devices. One can use these parameters in order to linearize the curve, in this case we talk about a gamma corrector.

In listing 1 one can see how a simple gamma correction for a 16 bit system in python looks. Presented will be a list of DAC values and a gamma value. The DAC values are whole numbers and work with 16 bit resolution from 0 to 2^16-1. To acheieve sensible results, one must normalize these values before the correction, into the range 0 to 1. After the correction one can convert the values back into the 'technical' form. One can see the result from such a correction in figure 2b. In this case I used gamma = 2.305. In order to arrive at this value, I firstly experimented with different values. Table 1 shows the results of my tests. For value 2.31 was the mean variance from the ideal line inferior than with 2.305, for which the maximal variance looked worse. At this point one must strike a compromise. In some applications will the entire luminance range of the device be divided into several blocks, and for each bloch will several several gamma values be used. With that kann one certainly improve the linearity.

2.1 ViSaGe

ViSaGe is one of the most widely distributed systems. The producer is "Cambridge Research Systems". One finds an overview at the following website: ... It allows the temporally exact presentation with fine shades of contrast and comes with functions which supposedly could be used for the programming of experiments. Out of here comes another problem: The experiments which were written for the ViSaGe platform only really run under ViSaGe. The core functionality is implemented in a provided DLL, which is to say that the system is limited to the windows OS. The source code is published nowhere, which is to say, that the exact functionality isn't transparent. One can control ViSaGe through matlab, or with Python through a library I wrote called PyVSG. There is a ready solution for LUT and pagecycling and as well an implement gamma corrector. There is a large buffer for video pages. There the pictures are handled individually, and it is rather hard to realize a complex animation.

ViSaGe commes with a special PCI Express Card, which must be installed, in order to be able to integrate with the graphics card system. As a result one cannot work with ViSaGe from a notebook, and a desktop is essential.

2.2 DATAPixx

The provider of DATAPixx is "VPixx Technologies" and an overview can be found here ... In comparison with ViSaGe, Datapixx is largely platform indepedent. For the most part, with little adjustment the system can be started under any POSIX compatible system. It comes with an open source API in C and can be used in arbitrary environments and programming languages. There are rather few provided functions. So there is no advertised LUT or PageCycling and no provided gamma correction like with ViSaGe. Each picture which will be loaded into the framebuffer of the graphics card passes through the DataPixx system and will displayed to the screen under the guidance of the lookup table. This approach provides much more flexibility: a programmer can decide themselves which graphics library shall be used. This leads as well to greater portability: a different scientist can try to perform the same experiment on a different platform. In the OS it will be configured as an additional monitor, so one can use the standard tools of the system. In linux for example there is one possibility, which is to adjust all three channels with the command xgamma.

Still another argument: The price of DATAPixx is cheaper than that of ViSaGe (at the time some 2000 euros cheaper). The customer support is also very good. Because of all these advantages my work is based in DATAPixx.

2.3 Linearization

In the introduction I mentioned that through the linearization of the luminance range several DAC values are lost. The reason for this is the uneven gradient of the luminance curve. In the area where the curve proceeds flatly, the DAC values will jump in order speedup and therefore acheieve a better linearization. The question remains open: how many still remain for disposal after the gamma correction of the experiment? As an experiment I measured the resulting luminance for all available DAC values from DATAPixx. Each value would be gathered 4 times and the mean value calculated. Firstly was the maximum luminance search for, for which I employed my monitor which reported a value of 486 cd/m2. The desired difference between two neighbouring values for the 16 bit DAC is consequently 486 / 2^16 = 0.0148. Now I can iterate over the measurement table and sort out all values with sufficient spacing between each other. In listing 2 is the corresponding source code in python. On my example system I achieved after linearization 26766 values.

When one has carried out a full measurement, there is no more direct need for the gamma correction. One can drop correct_gamma(), then will the function sort out suitable values from the entire area after the self procedure. The quality of the linearization of the curve can be improved here, when the procedure operates directly upon true hardware specific data. The only drawback is that additonal effort must be saved for the loading and processing of the data with the accumulated measurement data.

3 Monitors for Scientific Applications

For the choice of monitors must the following criterion be considered:

 - Higher refresh rate
 - Greater luminance range
 - Least possible dependence of luminance on coordinates.
 - Luminance of objects should be independence of the background

One can immediately notice how LCD and TFT monitors don't come into the question. The framerate there is not especially high, through which emerges the flickereffect through the superposition of two stimuli, which appears extremely inconvenient. Furthermore very strong luminance dependencies of the position on the screen are measurable (up to 25%)

Thus remain CRT monitors. In contrast with LCD here is there not only position dependent variations of luminance, but also background dependencies. Only through elaborate and expensive techniques can these artifacts be suffuciently reduced. A good example is the model SMM 21106 LS from Siemens. In figure 4 are luminances for the same rectangle are assigned to three different coordinates. Through the used scales the difference in luminances immmediately catches the eye, when one expresses these as percentages, the amount in the worst case is 2%. As a counter example I have repeated the same measurement for the Monitor N110S from Videoseven (which will be used in several computer rooms at the TU). There position dependent variance of the luminance amounts to the greatest value at 15.4%. With the Mitsubishi Diamond Pro 2070SB is this value still greater amounting to 18.64%.

Figure 5 shows the waste of luminance from a target on an ever brightening background. The entire background dependent variance amounts here roughly to 1.93% for the Siemens monitor. With N110 S this value amounts to 10.22%. The difference for these two devices will be clarified through figure 6.

The inexactitudes of the commercially available monitors are so high, that they lay above the perceptual threshold. Because of this will the application of these devices for scientific purposes be impossible. Specialized devices with special higher qualities like SMM 21106 are essential for psychophysical measurements. 

4 Software for Experiments

4.1 Minimal requirements

The to be implemented software must in the ver least allow the following operations:

 - Linearization of the luminance range
 - Image rendering with veritcal sync
 - Displaying of stimuli for a precise count of frames.
 - Depiction with LUT shift
 - Depicition with LUT and simultaneous paging
 - Immediate repomse to key presses
 - Sound response on prompt
 - Recording of answer with exact measurement of reaction time.

4.2 Realization

Psychophysical experiments are being implemented in a variety of different programming languages. More and more scientists are preferring the language python. It is simple to learn and relatively simple to extend. There are very many mathematical and graphical libraries for Python. It is an interpreted language, there are however many techniques in order to make the running time smaller.

Python comes with an open C API, which one can use in order to write distinct extension modules. A reference to this one can find on the site ... A rather large amount of code becomes necessary in order to comply with the appropriate form, so that Python can later use the module. One can find the complete source code with all the formalities for the datapixx interface under this address: ... Here I would like to introduce and clarify only those actually relevant functions.

As the first step one must open the interface with the datapixx device and the pass an object to the user which contains the necessary methods and attributes. The resulting function head looks like this: ...

py_dpixx_open() is the interal label of the function; for the python environment I will export this function under the simpler name open(). My function takes no parameters, but for that the placeholders must however be in accordance with the available specifications. In the beginning I declared several variables, the most important of which is 'self', they become an instance of the class, which the user later employs in order to integrate with the system. Since this function will always be called before all additional ones, I would like it to be used so that the priority of the process in the system is increased. Since the experiment must run with exact frame rates, the waiting time of the execution may only be very short, so that the program can manage all necessary calculations in the short time interval. We therefore want to stay as close as possible to the true time, which can be achieved with the following code snippet: ...

The highest possible priority for the round robin procedure will be determined and set for the particular process.

From now I begin to emply functions which are specified in the DATAPixx API. All declarations are to be found in the file 'libdpx.h'. There is no implementation documentation, one can only work at this place with the comments from the developer.

It (DPxOpen?) will try to open the interface. In the case that it doesn't succeed, will the initialization be immediately broken off.

DATAPixx has more operating modes. In the simplest case will the video data from the computer be redirect unchanged to the screen. Alternatively one can also work with lookup tables. For monochrome screens there is the possibility to employ the complete luminance range without lookup tables. Thereby will channel red and green be concatenated and treated as a 16 bit channel. In the beginning this is advisable, to engage direct piping.

The second command activates the regsiter of the system so as to kick all undertaken changes into effect.

Datapixx is connected to the computer via USB and DVI. Yet only the USB control pipe was employed. Now it will be controlled whether everything is in order with DVI, which is to say that there is data and it comes with a compatible frequency. Later will an accompanying small keyboard be employed for the the recording of responses, which normally be labelled response box. It has five comfortable keys, which one can illuminate individually by need. In order to work with this response box, the I/O ports from DATAPixx must be correctly adjusted. In the following are the necessary operations implemented: ...

Now the only remaining thing is to generate a python object and to give it back to the Python environment: ...

With the above written function can one generate an object in the Python environment. Memory becomes allocated for this object - if one doesn't need this object anymore, the used space should be freed, otherwise a so called "Memory Leak" arises. One wnats to avoid this, for which serves the following short function: ...

In most operating systems the refreshrate of the screen is displayed strongly rounded. This value is badly suited for the exact calculation of times. DATAPixx allows us to access the exact framerate. In order to access this data in Python I have written the following function, which encapsulates the original function and undertakes the conversion of the return value.

A further function performs the changing of the operating mode. It looks as well, like one in C processes parameters into python.

The following function illustrates the configuration of the lookup table. A list of 768 values is delivered from python. It depicts a sequence which consists of ret green and blue values. The information for all three channels must always be given. In the case where a monochrome monitor is to be used, only one channel is relevant - one traditionally selects green. 

In a simmilar way I have implemented a further series of useful functions. Among them some more for the use of the response box: Reading button presses, beeps, and lighting up buttons. Due to space constraints I can't comment extensively about all of them, the interested reader can always request to me the latest version of the source code. I am happily available for the disposal of questions.

4.3 

Through the use of Datapixx hardware, the necessary configuration of the operating system is rather simple and unproblematic. The first important point is the usage of the latest driver for the video card. For hardware acceleration the usage of binary drivers, which would be implemented directly by the provider of the graphics card, essential. These drivers are properietary and closed source, but are offered free of charge. Sadly in this situation the use of free drivers is not advisable, as they do not come close to supporting the full functionality of the hardware. The binary drivers will not normally be installed after the system installation and must be manually selected. For this mostly there are ready packages which one can install with a command. The latest and correct approach one finds in the documentation of the used distribution.

The next point which I would like to mention ist the setting of the refresh rate. This setting is saved in the configuration file of the XServer under "Modeline". The simplest way to compute the Modeline to use the program command 'cvt'. Usage looks like this: ...

Consequently is an appropriate modeline for a screen with Width 1024px, Height 768 px and a framerate of 133 Hz calculated.

Ever more people switch from CRT technology to LCD or TFT. There the frequencies are critically inferior and several software packages now won't work anymore for someone who wants to set a higher framerate. So this was the issue with my first attempt with X.org and the Nvidia driver. When frequencies were set above 85 Hz, would it be automatically reset to 85 Hz without any displayed warning. If a problem appears to be so, one needs additional settings. A complete functioning configurations file for nvidia one finds here: ...

In Linux there is besides the classic scheduler, which is responsible for the allocation of processing time, still a CPU Governor, which scales the clockrate of the processors while the working time dynamically follows a target policy. It is advisable to set the governor before the start of the experiment to 'Performance'. With that runs the processor statically with the highest possible frequency, which is set by the parameter 'scaling_max_frequency'. The changing of frequency during the running time of an experiment leads sometimes to the flickering of rendering. The changing of the governors is accomplished with the following command: cpufreq-selector -g performance

In the case where more CPUs or CPU cores are available, the governor must be set seperately for each unit.

In connection with DATAPixx one can use arbitrary libraries in order to generate and display stimuli. The chosen library must support additional monitors. Often this is not the case. Sometimes the application functions so long as one isn't changing the picture mode. This problem arose through trying out pygame and Vision Egg.

The software must support higher framerates. Sadly has the propogation of LCD and TFT screens also led to many software packages not at all being tested above 85 Hz. For scientific experiments frequencies above 130 Hz are however desired. There is a time dependent problem testable with 'pyglet'.

For very simple experiments, which require no Doublebuffering or Vertical sync, one can well employ the standard library for GUIs named TKinter. For complex experiments OpenGL is very advisable. Vertical Synchronization can be set simply for the application, there is Double buffering, pictures can be saved on the graphics card as textures and needn't always be transferred again from RAM. Very many functions are accelerated via graphics hardware, through which the CPU is relieved. The library is being constantly extended and improved. It is a standard and will as well in the future be ever more relevant.

In the last chapter I will introduce an experiment, which can be used as a template for the usage of OpenGL.

5. Control through luminance measurement

Quality control is an essential and very important component of any development process. In psycho physical experiments scientists very often use specially constructed images, which cause optical deceptions. The correctness of the depictions only be evaluated limitedly with our eyes. For the examination one takes special luminace measurement devices, with which the brightness of the selected luminance range can be ascertained. When stimuli are superimposed with short presentation times and fine contrasts, it is impossible that a human observer is in the situation to assess mistakes from selected frames. In this case is a device necessary, that determines the luminance with a higher rate and is consequently suitable for the analysis of individual frames. In the following subchapter I will introduce several oft used devices.

5.1 CRS OptiCAL

In the ViSaGe environment are standard uses of CRS OptiCAL proposed. It is developed by the same company and is being employed for the calibration of ViSaGe systems. It can measure luminance up to 2500 cd/m^2 with a resolution of 0.1 cd/m^2 - which is sufficient on its own for the use of 16 bit DACs. The device is fixed to the surface of the screen, thereby one cannot examine viewing angle dependence. The device receives light from a relatively large area, as such there influence from the immediate vicinity when measuring small areas, which must be regarded. OptiCAL is accessed over the serial RS 232 interface. One can consequently automate complete arbitrary measurements. It is very important, that the scientist needn't be present the entire measurement time, because some measurements can last more than a day. For the application via a python script there is a moduel called pyoptical from Valentin Haenel. If the ViSaGe software is installed, one can also deply my wrapper script 'OptiCAL.py'. The time resolution is examplified in figure 7. In one trial I displayed an alrea with luminance from 570 cd/m^2 for different frame counts and carried out with OptiCAL the measuremtn for each interval. It emphasises that OptiCAL releases correct values not until 36 frames. Consequently it is clear, that this device is not suitable for the monitoring of individual frames. 

5.2 Konica Menolta LS-100

LS-100 is a light and portable device, which althrough for automated measurements with a PC it is also suitable for manual applications. In comparison with OptiCAL, it needn't be fixed to the monitor. It can be held in hand or mounted upon a tripod. Consequently it allows the measurement of brightness from different distances and angles. Additional filters and lenses can be attached to the objective with a screw cap, which allows an accurate measurement of a wide spectrum under different conditions. It is certainly a convenience in comparison with OptiCAL. On one hand is it possible to focus on very small areas (until 0.5 mm), and on the other hand one can reduce the scatter of measurement values through targeted deploymnet of a neutral density filter.

Also for this device I implemented a python interface and carried out a similar measurement like in the previous subsection. One can see the result in figure 8. I employed the slow mode, because it is more suitable for CRT Monitors according to the manual. Like one sees, the correct value is not gathered until 180 Frames. Consequently is the LS-110 also not usable, if the purpose is exact frame measurements.

5.3 Distinct Microcontroller Project

Since no suitable tool was available, I resolved to independently develop a suitable device. Even though a ready solution in this sphere exists, is the price for the ready device astronomically high. Through skillful choice of semiconductors can a good result be obtained as well with little investment of money. These days the deployment of extremely high integrated semiconductors preferred to the design with individual parts. This simplifies the development process and minimizes the time to market factor. One speaks in this context of "Rapid Development". I will follow this strategy in order to acheive the planned goal.

5.3.1 Employed hardware components

In digital measurement technologies must each physical quantity which shall be measured first be set to an electrical potential. Not untill than can an ADC until take a sample and pass along the result. For photometric measurements one employs photodiodes. The incident light sets the charge in the semiconductor free, which leads to the decline of the electrical resistance. If one therefore applies a potential to the photodiode, different large currents flow through the semiconductor as a result of its dependence on the incident light intensity. One cannot however measure the current directly with a microcontroller module. In this situation is the application of a trans impedence converter necessary. It is a very widespread amplification circuit, which in this case converts the photostream into a potential value. both together, photodiode and transimpedanzconverter (with amplifier), can one produce a chip.

For my measurement device I used the JI 546 Element from ifw optronics GmbH. It has a high bandwidth of 120 kHz and the range of the outgoing potential can easy be set from 0 to 5 V, consequently no conditiong before the ADC is necessary. The internal wiring is depicted in figure 9. ...

For the automated recording of measurement data and transmission to the PC I apllied a MEGA128-USB module. The following components are housed in a compact board:

 - Atmega 128-16MU Microcontroller
 - CP2102 USB-USART-Bridge
 - 16 MHz Quarz
 - MC34064D undervoltage detector
 - ADC Reference potential filter (10 uH)

A picture of this can be seen in figure 9b.

A stabilized and aligned balanced potential is necessary for the supply of the JI 546. Balanced potential can be easily generated by a labor generator - these in general have a large size, since however I'm interested in a most portable solution, I employ a 15 V generator PSA15R-150P from Phihong and two potential regulators for +10V and +5V. Consequently I receive a floating potential of +5V, which will be employed as ground for the JI 546. Relative to this are the +10 and 0 V (Earth) symmetric and and be used as a potential supply of the operations amplifier. The voltage regulator on its own is not sufficient to filter out the existing net noise. For this purpose will capacitors with different properties be deployed. Electrical capacitors with very high capacitance and greater internal resistance filter oscillations with greater amplitude and smaller frequency- foil capacitors with lower capacitance small internal resistance neutralize high frequency noise with lower amplitude.

For the design of the necessary circuit and creation of the boardplan I used the prorgam EAGLE from CadSoft. My circuit diagram is depicted in figure 10 and it is there to see in the corresponding figure 11.

5.3.2 Programming

The module that I employed, MEGA128-USB, allows the direct programming over the USB interface - therefore no additional programming is necessary. The accompanying firmware is preset so that after the start of the microcontroller will firstly a bootloader be executed. In the case where during its execution pins RESET and PG4 are grounded, will the saved program not start at all and the device can receive a new firmware.

For the implementation of the necessary functions I used AVR studio from Atmel. Before sampling can ensue, the ADC system of the Microcontroller must be configured and be engaged. For this I used the following code fragment: ...

In the next extract is the next value from the ADC waited for, subsequently will the result be saved in register r16 and r17 and the next sample begun.

The transmission of the measured values happens over the serial interface USART, for which the functions PutChar and PutCharL are relevant. The first transmits the MSB side and the second the LSB side.

The main loop serves to constantly sample and send the result to the PC.

The client is being implemented in Python, its task consisting in the establishment the connection with the photometer over USB, to receive the ADC values and to convert them into floating point numbers.

5.3.3 Exact frame measurement

With the ADC of Atmega 128 one can acheive sampling rates of 10 kHz, which means that with a refreshrate of 130 Hz some 100 samples per frame will be taken. Consequently I don't need to carry out a measurement for the determination of the smallest presentation interval like for Optical and LS-100, since they lay well within a frame. Instead I show a figure permanent on the screen and gather 1000 samples consecutively. The result can be seen in figure 12. In figure 13 is the luminance process depicted while a frame is being grown. One should consider, that with rising luminance, the measured potential becomes smaller. It can lead to confusion, therefore the measured values become inverted before the graphical representation.

4.995 is the maximal potential that can be measured.

Like one sees, the sample rate is sufficient, in order to count and analyze individual frames. With this can problems with rendering, e.g. missing frames or so called 'Tearing' (when parts of sequential frames mix), can be noticed without problem. The unit of the coordinate axes are arbitrary. The translation from inverted voltage values with brightness units cd/m^2 must be calibrated with the device. At the time I am looking into this possibility. Afterwards is the device ready for deployment.

In the case where a higher sampling rate is desired, one needs an aditional ADC chip, which connects to the microcontroller over SPI or TWI interface. I have already developed an extended version with MCP3208 Chip, which samples with 100 kHz, this however serves no purpose for this work. One should consider, that the maximum transmision rate of the Atmega 128 lies at 250 kbit/sec. These don't reach 100 kHz any more in order that the measurement data is conveyed in real time to the client. In such a situation a datablock must first be saved on the microcontroller module in order to arrive later at the client.

6. Sample experiment

6.1 Writing of the experiment

In this chapter I will introduce a sample experiment which shall serve to test the functionality of the new experiment environment. With this I knowingly abandon standard puts such as preperation of the design matrix and saving of the recorded answers for various research subjects in a datastructure or databank. The key point lays in the basic function, which I try to present as clearly as possible, so that this experiment can serve for future experiments. Missing elements can be freely implemented.

One trial of this experiment consists of a gabor stimulus like in figure 14, first mask like in 15A and then second mask with a reversed slant like in 15b. All pictures will be shown for exactly one frame. The show proceeds with vertical synchronization.

In each trial the contrast for the stimulus frame will be changed, for which the lookup table will be calculated and set each time. the contrast of the max stays unchanged.

The beginning of the first trial will be announced with a tone, at the same time as all the keys of the response box are quickly lit up.

The user can at any arbitrary time cancel the experiment by pressing the middle button, for which the status of the response box must be evaluated in every frame. On cancellation will the exact reaction time be shown.

6.2 Implementation in Python

The core functionality is implemented in the class ImageLaoder. Execution begins with the function main(), which looks like the following: ...

The second to last line indicates that before the transition into the main loop the function InitGL of the class ImageLoader will be called. I used this method in order to perform all necessary settings of the graphics environment and to allocate all necessary variable initializations, before the experiment starts.

In the above written function will the method load_texture() be employed in order to load the stimulus into texture memory. Here is the implementation: ...

In the main loop a rendering function is continually called. This is for the timely responsive changing of picture and LUT.

In order to activate vertical synchronization in GLX, the environment variable __GL_SYNC_TO_VBLANK must be set to 1. One can ensure this directly in the experiment script: ...

Complete source code can be obtained from the following address: ...

6.3 Conclusions

The planned features of the presentation became achieved. Stimuli were shown for exactly one frame at a time. Vertical synchronization was satisfied. All human observers saw the superposition of the three used pictures. Through the framerate of 130 Hz was a light flicher in the middle of the picture seen. This frequency was also not so high thus staying below the perceptual threshold. If one superimposes only the two masks without stimulus, these criteria were also fulfilled. The superposition look in this case completely stable.
